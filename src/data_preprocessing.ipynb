{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec037ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f5c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/diabetes.csv')\n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6cf6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero counts before replacement:\n",
      "Glucose            5\n",
      "BloodPressure     35\n",
      "SkinThickness    227\n",
      "Insulin          374\n",
      "BMI               11\n",
      "dtype: int64\n",
      "\n",
      "Missing values after replacement:\n",
      "Pregnancies                   0\n",
      "Glucose                       5\n",
      "BloodPressure                35\n",
      "SkinThickness               227\n",
      "Insulin                     374\n",
      "BMI                          11\n",
      "DiabetesPedigreeFunction      0\n",
      "Age                           0\n",
      "dtype: int64\n",
      "\n",
      "Duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values encoded as zeros\n",
    "\n",
    "zero_as_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "print(\"\\nZero counts before replacement:\")\n",
    "print((X[zero_as_missing] == 0).sum())\n",
    "\n",
    "X[zero_as_missing] = X[zero_as_missing].replace(0, np.nan)\n",
    "\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(X.isna().sum())\n",
    "\n",
    "# Remove duplicate rows\n",
    "\n",
    "X['Outcome'] = y\n",
    "before_dupes = X.shape[0]\n",
    "X = X.drop_duplicates()\n",
    "after_dupes = X.shape[0]\n",
    "\n",
    "print(f\"\\nDuplicates removed: {before_dupes - after_dupes}\")\n",
    "\n",
    "y = X['Outcome']\n",
    "X = X.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e09c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature list after engineering:\n",
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'BMI_Age']\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# BMI * Age interaction feature\n",
    "X['BMI_Age'] = X['BMI'] * X['Age']\n",
    "\n",
    "print(\"\\nFeature list after engineering:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbcbfe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset splits:\n",
      "Train: (537, 9)\n",
      "Validation: (115, 9)\n",
      "Test: (116, 9)\n",
      "\n",
      "Class distribution check (before SMOTE):\n",
      "Train: Outcome\n",
      "0    0.651769\n",
      "1    0.348231\n",
      "Name: proportion, dtype: float64\n",
      "Validation: Outcome\n",
      "0    0.652174\n",
      "1    0.347826\n",
      "Name: proportion, dtype: float64\n",
      "Test: Outcome\n",
      "0    0.646552\n",
      "1    0.353448\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train / Validation / Test Split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nDataset splits:\")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Validation:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n",
    "\n",
    "print(\"\\nClass distribution check (before SMOTE):\")\n",
    "print(\"Train:\", y_train.value_counts(normalize=True))\n",
    "print(\"Validation:\", y_val.value_counts(normalize=True))\n",
    "print(\"Test:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14639541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checks after preprocessing:\n",
      "Any NaNs in processed train data: False\n",
      "Mean of first 5 features (train): [ 2.31554895e-17  1.98475625e-17 -2.61326239e-16  1.90205807e-16\n",
      "  1.32317083e-16]\n",
      "Std of first 5 features (train): [1. 1. 1. 1. 1.]\n",
      "Processed feature count: 9\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "numeric_features = X.columns\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_pipeline, numeric_features)\n",
    "])\n",
    "\n",
    "# Fit ONLY on training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Checks after preprocessing\n",
    "print(\"Checks after preprocessing:\")\n",
    "\n",
    "print(\"Any NaNs in processed train data:\",\n",
    "    np.isnan(X_train_processed).any())\n",
    "\n",
    "print(\"Mean of first 5 features (train):\",\n",
    "    X_train_processed.mean(axis=0)[:5])\n",
    "\n",
    "print(\"Std of first 5 features (train):\",\n",
    "    X_train_processed.std(axis=0)[:5])\n",
    "\n",
    "print(\"Processed feature count:\",\n",
    "    X_train_processed.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c08943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution BEFORE SMOTE:\n",
      "Counter({0: 350, 1: 187})\n",
      "\n",
      "Class distribution AFTER SMOTE:\n",
      "Counter({1: 350, 0: 350})\n"
     ]
    }
   ],
   "source": [
    "# Handle Class Imbalance using SMOTE\n",
    "\n",
    "print(\"\\nClass distribution BEFORE SMOTE:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(\n",
    "    X_train_processed, y_train\n",
    ")\n",
    "\n",
    "print(\"\\nClass distribution AFTER SMOTE:\")\n",
    "print(Counter(y_train_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901f8329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline reload successful: True\n",
      "\n",
      "Preprocessing complete.\n",
      "Final training set shape after SMOTE: (700, 9)\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessing pipeline\n",
    "\n",
    "joblib.dump(preprocessor, 'preprocessing_pipeline.pkl')\n",
    "\n",
    "# Reload check (reproducibility)\n",
    "loaded_preprocessor = joblib.load('preprocessing_pipeline.pkl')\n",
    "X_test_check = loaded_preprocessor.transform(X_test)\n",
    "\n",
    "print(\"\\nPipeline reload successful:\",\n",
    "    X_test_check.shape == X_test_processed.shape)\n",
    "\n",
    "print(\"\\nPreprocessing complete.\")\n",
    "print(\"Final training set shape after SMOTE:\", X_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34f8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data exported for model training.\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets for model training\n",
    "processed_data = {\n",
    "    'X_train': X_train_balanced,\n",
    "    'y_train': y_train_balanced,\n",
    "    'X_val': X_val_processed,\n",
    "    'y_val': y_val,\n",
    "    'X_test': X_test_processed,\n",
    "    'y_test': y_test\n",
    "}\n",
    "\n",
    "joblib.dump(processed_data, '../data/processed_diabetes_data.pkl')\n",
    "\n",
    "print(\"Processed data exported for model training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
